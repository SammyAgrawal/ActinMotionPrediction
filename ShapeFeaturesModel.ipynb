{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use classic CV features in combination with Deep Learning to predict cell movements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "from skimage.measure import centroid\n",
    "import skimage.measure as skm\n",
    "from torch.utils.data import random_split\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_features(binary, feature_length=20, num_samples=180):\n",
    "    def radial_distance(binary, theta):\n",
    "        height, width = binary.shape\n",
    "        center = [width // 2, height // 2]\n",
    "        def test_r(r):\n",
    "            x_test, y_test = center[0] + r*np.cos(theta), center[1] + r*np.sin(theta)\n",
    "            if(x_test >= width or y_test > height or x_test < 0 or y_test < 0):\n",
    "                return(False)\n",
    "            return(binary[int(y_test), int(x_test)])\n",
    "        # calculate distance to the nearest pixel\n",
    "        r = max(height, width)\n",
    "        while(not test_r(r)): # start from edge come inside until hit cell\n",
    "            r -= 1\n",
    "        return(r)\n",
    "\n",
    "    test_angles = np.linspace(0, 2*np.pi, num_samples)\n",
    "    distances = np.array([radial_distance(binary, angle) for angle in test_angles])\n",
    "    fft_coefficients = np.fft.rfft(distances)\n",
    "\n",
    "    features = np.abs(fft_coefficients[:feature_length])\n",
    "    features = features / np.sum(features)\n",
    "    return(features, (distances, fft_coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(patches, masks):\n",
    "    image, binary = patches, masks.astype(np.uint8)\n",
    "    zernike = mahotas.features.zernike_moments(binary, max(binary.shape)/2, degree=8)\n",
    "    #zernike = zernike / zernike.sum()\n",
    "    haralick = mahotas.features.haralick(image.astype(np.uint16)).mean(axis=0)\n",
    "    #haralick = haralick / haralick.sum()\n",
    "    shape, info = shape_features(binary, 20)\n",
    "    #print(f\"Zernike: {zernike.shape}, Haralick: {haralick.shape}, Radial Shape: {shape.shape}\")\n",
    "    return(np.concatenate([zernike, haralick, shape]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(boxes, masks):\n",
    "        N = len(masks)\n",
    "        res = []\n",
    "        centroids = [skm.centroid(binary.astype(np.uint8)) for binary in masks]\n",
    "        for i in range(N):\n",
    "            c = centroids[i]\n",
    "            ymin, xmin = boxes[i][:2]\n",
    "            res.append([xmin+c[0], ymin+c[1]])\n",
    "        return(np.array(res) - res[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocities(centroids):\n",
    "    vels = [0] * len(centroids)\n",
    "    vels[0] = np.array([0,0])\n",
    "    for i in range(1,len(centroids)):\n",
    "        vels[i] = centroids[i] - centroids[i-1]\n",
    "    return vels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_padding =  300\n",
    "box_shape = (180, 180)\n",
    "X = 10\n",
    "\n",
    "class VelocitiesClassicDataset(torch.utils.data.Dataset):\n",
    "    #input will be a Directory name, function is TO DO\n",
    "    def __init__(self,files, X=X):\n",
    "        self.video_extractor = VideoDataMIP(files)\n",
    "        self.cell_dict = []\n",
    "\n",
    "        for i in files:\n",
    "            self.video_extractor.extract_all_traces(i[1], X)\n",
    "\n",
    "        for key in self.video_extractor.data:\n",
    "            entry = self.video_extractor.data[key][\"traces\"]\n",
    "            for cell in entry:\n",
    "                features = [featurize(p,m) for p,m in zip(cell[\"patches\"], cell[\"masks\"])]\n",
    "                velocities = [np.array(p) for p in get_velocities(get_centroids(cell[\"boxes\"], cell[\"masks\"]))]\n",
    "                self.cell_dict.append((features, velocities)) #cell dict is a list of 3 types by sequence\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cell_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # tuple of features, velocities\n",
    "        return  self.cell_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in MIP 3\n",
      "Loading dicty_factin_pip3-03_MIP.czi with dims [{'X': (0, 474), 'Y': (0, 2048), 'C': (0, 2), 'T': (0, 90)}]\n",
      "frames 3: (90, 2048, 474)\n",
      "Loading in MIP 6\n",
      "Loading dicty_factin_pip3-06_MIP.czi with dims [{'X': (0, 474), 'Y': (0, 2048), 'C': (0, 2), 'T': (0, 241)}]\n",
      "frames 6: (241, 2048, 474)\n",
      "Loading in MIP 9\n",
      "Loading dicty_factin_pip3-09_MIP.czi with dims [{'X': (0, 474), 'Y': (0, 2048), 'C': (0, 2), 'T': (0, 241)}]\n",
      "frames 9: (241, 2048, 474)\n",
      "Extracting traces from 0:10\n",
      "Extracting traces from 10:20\n",
      "Extracting traces from 20:30\n",
      "Extracting traces from 30:40\n",
      "Extracting traces from 40:50\n",
      "Extracting traces from 50:60\n",
      "Extracting traces from 60:70\n",
      "Extracting traces from 70:80\n",
      "Extracting traces from 80:90\n",
      "Extracting traces from 0:10\n",
      "Extracting traces from 10:20\n",
      "Extracting traces from 20:30\n",
      "Extracting traces from 30:40\n",
      "Extracting traces from 40:50\n",
      "Extracting traces from 50:60\n",
      "Extracting traces from 60:70\n",
      "Extracting traces from 70:80\n",
      "Extracting traces from 80:90\n",
      "Extracting traces from 90:100\n",
      "Extracting traces from 100:110\n",
      "Extracting traces from 110:120\n",
      "Extracting traces from 120:130\n",
      "Extracting traces from 130:140\n",
      "Extracting traces from 140:150\n",
      "Extracting traces from 150:160\n",
      "Extracting traces from 160:170\n",
      "Extracting traces from 170:180\n",
      "Extracting traces from 180:190\n",
      "Extracting traces from 190:200\n",
      "Extracting traces from 200:210\n",
      "Extracting traces from 210:220\n",
      "Extracting traces from 220:230\n",
      "Extracting traces from 230:240\n",
      "Extracting traces from 0:10\n",
      "Extracting traces from 10:20\n",
      "Extracting traces from 20:30\n",
      "Extracting traces from 30:40\n",
      "Extracting traces from 40:50\n",
      "Extracting traces from 50:60\n",
      "Extracting traces from 60:70\n",
      "Extracting traces from 70:80\n",
      "Extracting traces from 80:90\n",
      "Extracting traces from 90:100\n",
      "Extracting traces from 100:110\n",
      "Extracting traces from 110:120\n",
      "Extracting traces from 120:130\n",
      "Extracting traces from 130:140\n",
      "Extracting traces from 140:150\n",
      "Extracting traces from 150:160\n",
      "Extracting traces from 160:170\n",
      "Extracting traces from 170:180\n",
      "Extracting traces from 180:190\n",
      "Extracting traces from 190:200\n",
      "Extracting traces from 200:210\n",
      "Extracting traces from 210:220\n",
      "Extracting traces from 220:230\n",
      "Extracting traces from 230:240\n"
     ]
    }
   ],
   "source": [
    "mip_video_files = [\n",
    "    ('mip', 3),\n",
    "    ('mip', 6),\n",
    "    ('mip', 9)\n",
    "]\n",
    "dataset = VelocitiesClassicDataset(mip_video_files, X) # file, S, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, eval, test = random_split(dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "input_datasets = {}\n",
    "input_datasets[\"train\"] = train\n",
    "input_datasets[\"eval\"] = eval\n",
    "input_datasets[\"test\"] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    current_features = [b[0] for b in batch]\n",
    "    current_offset = [b[1] for b in batch] \n",
    "    return torch.tensor(np.stack(current_features)).to(torch.float32), torch.tensor(np.stack(current_offset)).to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(\n",
    "    input_datasets['train'],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "dataloaders['test'] = torch.utils.data.DataLoader(\n",
    "    input_datasets['test'],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "dataloaders['eval'] = torch.utils.data.DataLoader(\n",
    "    input_datasets['eval'],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([4, 10, 58]) Velocities torch.Size([4, 10, 2])\n",
      "Input: torch.Size([3, 10, 58]) Velocities torch.Size([3, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloaders['eval']:\n",
    "    print(\"Input:\", batch[0].shape, \"Velocities\", batch[1].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        #Flatten the input from (4, 9, 2) to (4, 18)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(58, 2) \n",
    "        # self.fc2 = nn.Linear(32,16)\n",
    "        # self.fc3 = nn.Linear(16,8)torch loss functions\n",
    "        # self.fc4 = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) \n",
    "        # x = torch.relu(self.fc1(x)) \n",
    "        # x = torch.relu(self.fc2(x))\n",
    "        # x = torch.relu(self.fc3(x))\n",
    "        x = self.fc1(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True) #stacking 2 LSTMs\n",
    "        # hidden out output\n",
    "        #  2 bc x y centroid\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "    def forward(self, input):\n",
    "        h0 = torch.zeros(self.num_layers, input.size(0), self.hidden_dim).to(input.device)\n",
    "        c0 = torch.zeros(self.num_layers, input.size(0), self.hidden_dim).to(input.device)\n",
    "        out, _ = self.lstm(input, (h0, c0))\n",
    "\n",
    "        out = self.fc(out)\n",
    "        final = out[:,-1,:]\n",
    "        out = torch.sigmoid(final) * max_padding\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "sequence_length = 10 #how many frames we process per input\n",
    "\n",
    "# model = LSTM(input_size, hidden_size, num_layers)\n",
    "model = LSTM(input_size=58, hidden_dim = 58)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "# dummy_input_data = torch.randn(batch_size, 10, input_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch in dataloaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, outputs = batch[0], batch[1]\n",
    "        inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "        inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "        pred = model(inputs[:, :sequence_length-1, :])\n",
    "        # print(inputs[:, sequence_length-1:sequence_length, :].shape)\n",
    "        # print(pred.shape, outputs[:,-1,:].shape)\n",
    "        # print(f\"pred: {pred}\")\n",
    "        # print(f\"outputs: {outputs.data[:,-1,:]}\")\n",
    "        # total_correct += torch.sum(torch.eq(pred, outputs[:,-1,:]))\n",
    "        loss = criterion(pred, outputs[:,-1,:])\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print(f\"training loss: {total_loss / len(dataloaders['train'])}, training accuracy: {total_correct / len(dataloaders['eval'])}\")\n",
    "    print(f\"training loss: {total_loss / len(dataloaders['train'])}\")\n",
    "    return model\n",
    "\n",
    "def eval():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloaders['eval']:\n",
    "            inputs, outputs = batch[0], batch[1]\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "            pred = model(inputs[:, :sequence_length-1, :])     \n",
    "            loss = criterion(pred, outputs[:,-1,:])\n",
    "            total_loss += loss.item()\n",
    "    print(f\"validation loss: {total_loss / len(dataloaders['eval'])}\")\n",
    "    return total_loss / len(dataloaders['eval'])\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        train()\n",
    "        curr_acc = eval()\n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "training loss: 2663.994289452689\n",
      "validation loss: 841.1459820866585\n",
      "Epoch: 1\n",
      "training loss: 672.3464625494821\n",
      "validation loss: 818.6365978240967\n",
      "Epoch: 2\n",
      "training loss: 666.533123588562\n",
      "validation loss: 810.9657469511033\n",
      "Epoch: 3\n",
      "training loss: 665.2561683041708\n",
      "validation loss: 805.1799789190293\n",
      "Epoch: 4\n",
      "training loss: 662.3853049210139\n",
      "validation loss: 803.1874762773514\n",
      "Epoch: 5\n",
      "training loss: 661.9053534439632\n",
      "validation loss: 801.6749158978462\n",
      "Epoch: 6\n",
      "training loss: 661.5863018700055\n",
      "validation loss: 801.2095357179642\n",
      "Epoch: 7\n",
      "training loss: 661.3778661676815\n",
      "validation loss: 800.1282931089402\n",
      "Epoch: 8\n",
      "training loss: 661.2180553981236\n",
      "validation loss: 798.7664747834206\n",
      "Epoch: 9\n",
      "training loss: 661.5320546797344\n",
      "validation loss: 817.8248416304589\n",
      "Epoch: 10\n",
      "training loss: 660.8920964547566\n",
      "validation loss: 797.0986922502518\n",
      "Epoch: 11\n",
      "training loss: 660.779383967604\n",
      "validation loss: 796.4595306634903\n",
      "Epoch: 12\n",
      "training loss: 661.6542941434043\n",
      "validation loss: 972.4010528564453\n",
      "Epoch: 13\n",
      "training loss: 660.7181191887174\n",
      "validation loss: 795.4632303714752\n",
      "Epoch: 14\n",
      "training loss: 660.7512590442385\n",
      "validation loss: 795.1987002491951\n",
      "Epoch: 15\n",
      "training loss: 660.8509310637202\n",
      "validation loss: 795.2493834376335\n",
      "Epoch: 16\n",
      "training loss: 660.7572633930615\n",
      "validation loss: 794.88407818079\n",
      "Epoch: 17\n",
      "training loss: 860.5384554011481\n",
      "validation loss: 794.3793836891651\n",
      "Epoch: 18\n",
      "training loss: 660.750611788886\n",
      "validation loss: 794.8838693380355\n",
      "Epoch: 19\n",
      "training loss: 660.7603438173022\n",
      "validation loss: 794.6316419541836\n",
      "Epoch: 20\n",
      "training loss: 661.2946888651167\n",
      "validation loss: 799.6476057589055\n",
      "Epoch: 21\n",
      "training loss: 661.0183322668075\n",
      "validation loss: 799.2404311418534\n",
      "Epoch: 22\n",
      "training loss: 660.5749510220119\n",
      "validation loss: 793.9888221025467\n",
      "Epoch: 23\n",
      "training loss: 660.6139601622309\n",
      "validation loss: 796.1966809153557\n",
      "Epoch: 24\n",
      "training loss: 660.5875651632036\n",
      "validation loss: 793.7301401019097\n",
      "Epoch: 25\n",
      "training loss: 660.7079674209867\n",
      "validation loss: 798.8797780036926\n",
      "Epoch: 26\n",
      "training loss: 660.8754178455898\n",
      "validation loss: 793.3435391008854\n",
      "Epoch: 27\n",
      "training loss: 660.6911085282053\n",
      "validation loss: 969.2673020839691\n",
      "Epoch: 28\n",
      "training loss: 660.5875631775175\n",
      "validation loss: 793.6979941606521\n",
      "Epoch: 29\n",
      "training loss: 660.7163558278766\n",
      "validation loss: 794.4373586714268\n",
      "Epoch: 30\n",
      "training loss: 660.6163850103106\n",
      "validation loss: 792.999437469244\n",
      "Epoch: 31\n",
      "training loss: 660.8370165654591\n",
      "validation loss: 793.3385211646557\n",
      "Epoch: 32\n",
      "training loss: 681.4722905022758\n",
      "validation loss: 792.827396696806\n",
      "Epoch: 33\n",
      "training loss: 660.9752202204296\n",
      "validation loss: 797.3730514109135\n",
      "Epoch: 34\n",
      "training loss: 660.8358879770551\n",
      "validation loss: 792.9010990083218\n",
      "Epoch: 35\n",
      "training loss: 660.8453426633563\n",
      "validation loss: 793.2978327512741\n",
      "Epoch: 36\n",
      "training loss: 661.1472620231765\n",
      "validation loss: 968.501740694046\n",
      "Epoch: 37\n",
      "training loss: 660.7588464643273\n",
      "validation loss: 792.4894928574562\n",
      "Epoch: 38\n",
      "training loss: 660.5877779892513\n",
      "validation loss: 792.5321069896221\n",
      "Epoch: 39\n",
      "training loss: 660.9113391314235\n",
      "validation loss: 792.9068170428276\n",
      "Epoch: 40\n",
      "training loss: 660.7547429221017\n",
      "validation loss: 792.3279859483242\n",
      "Epoch: 41\n",
      "training loss: 660.7630795904569\n",
      "validation loss: 792.3365292489528\n",
      "Epoch: 42\n",
      "training loss: 860.9508102902345\n",
      "validation loss: 792.291512453556\n",
      "Epoch: 43\n",
      "training loss: 660.9106738158634\n",
      "validation loss: 792.9187897384166\n",
      "Epoch: 44\n",
      "training loss: 660.6596339719636\n",
      "validation loss: 792.6465131133795\n",
      "Epoch: 45\n",
      "training loss: 660.8402241962297\n",
      "validation loss: 792.3559652984143\n",
      "Epoch: 46\n",
      "training loss: 660.5939925193786\n",
      "validation loss: 792.0668227717281\n",
      "Epoch: 47\n",
      "training loss: 660.9347543614251\n",
      "validation loss: 791.991971874237\n",
      "Epoch: 48\n",
      "training loss: 660.8839293513979\n",
      "validation loss: 792.488270330429\n",
      "Epoch: 49\n",
      "training loss: 660.8825833644186\n",
      "validation loss: 791.992578291893\n",
      "Epoch: 50\n",
      "training loss: 660.7521173409053\n",
      "validation loss: 791.9931236445904\n",
      "Epoch: 51\n",
      "training loss: 661.0761606139796\n",
      "validation loss: 791.9039289623499\n",
      "Epoch: 52\n",
      "training loss: 660.7436363628932\n",
      "validation loss: 793.5870893120766\n",
      "Epoch: 53\n",
      "training loss: 660.7970890266555\n",
      "validation loss: 791.4862318873405\n",
      "Epoch: 54\n",
      "training loss: 660.7869851725442\n",
      "validation loss: 792.7008006930351\n",
      "Epoch: 55\n",
      "training loss: 660.7465329970632\n",
      "validation loss: 791.7924982607365\n",
      "Epoch: 56\n",
      "training loss: 661.1218142696789\n",
      "validation loss: 791.9374663859605\n",
      "Epoch: 57\n",
      "training loss: 661.6137285062244\n",
      "validation loss: 792.3632467269897\n",
      "Epoch: 58\n",
      "training loss: 661.0572917376246\n",
      "validation loss: 794.5316716849804\n",
      "Epoch: 59\n",
      "training loss: 660.9991152541978\n",
      "validation loss: 792.4255286216736\n",
      "Epoch: 60\n",
      "training loss: 660.8719205175128\n",
      "validation loss: 967.1710170328618\n",
      "Epoch: 61\n",
      "training loss: 660.9079043728965\n",
      "validation loss: 791.7419663965702\n",
      "Epoch: 62\n",
      "training loss: 660.7593235339438\n",
      "validation loss: 791.6853506594896\n",
      "Epoch: 63\n",
      "training loss: 660.7155985866274\n",
      "validation loss: 791.5808471560479\n",
      "Epoch: 64\n",
      "training loss: 660.8496975864683\n",
      "validation loss: 966.4855745136738\n",
      "Epoch: 65\n",
      "training loss: 660.6860644068037\n",
      "validation loss: 796.7935192108155\n",
      "Epoch: 66\n",
      "training loss: 660.9653581755501\n",
      "validation loss: 791.2408517658711\n",
      "Epoch: 67\n",
      "training loss: 660.6388577137675\n",
      "validation loss: 791.5921748965978\n",
      "Epoch: 68\n",
      "training loss: 660.7831041003976\n",
      "validation loss: 791.569091296196\n",
      "Epoch: 69\n",
      "training loss: 660.7903908405985\n",
      "validation loss: 791.6347793936729\n",
      "Epoch: 70\n",
      "training loss: 660.8271132579872\n",
      "validation loss: 791.8178286194801\n",
      "Epoch: 71\n",
      "training loss: 660.7745191505977\n",
      "validation loss: 791.719230273366\n",
      "Epoch: 72\n",
      "training loss: 660.8899925129754\n",
      "validation loss: 792.1566216945648\n",
      "Epoch: 73\n",
      "training loss: 661.0045430455889\n",
      "validation loss: 967.2325280219317\n",
      "Epoch: 74\n",
      "training loss: 660.790855867522\n",
      "validation loss: 791.5572154164314\n",
      "Epoch: 75\n",
      "training loss: 660.8310167108264\n",
      "validation loss: 792.0940400719643\n",
      "Epoch: 76\n",
      "training loss: 665.3366848979678\n",
      "validation loss: 792.0772850036622\n",
      "Epoch: 77\n",
      "training loss: 660.9349859850747\n",
      "validation loss: 791.6184125483036\n",
      "Epoch: 78\n",
      "training loss: 660.7819010087422\n",
      "validation loss: 791.6538704425096\n",
      "Epoch: 79\n",
      "training loss: 660.9472809672355\n",
      "validation loss: 791.529346704483\n",
      "Epoch: 80\n",
      "training loss: 661.8901360929012\n",
      "validation loss: 791.0550050228834\n",
      "Epoch: 81\n",
      "training loss: 660.8492240147931\n",
      "validation loss: 793.2644079446793\n",
      "Epoch: 82\n",
      "training loss: 661.1414057901927\n",
      "validation loss: 791.7868610501289\n",
      "Epoch: 83\n",
      "training loss: 661.0184193066189\n",
      "validation loss: 791.0169658213854\n",
      "Epoch: 84\n",
      "training loss: 660.7933536257062\n",
      "validation loss: 791.037571322918\n",
      "Epoch: 85\n",
      "training loss: 661.0377469650336\n",
      "validation loss: 793.2635291099548\n",
      "Epoch: 86\n",
      "training loss: 660.9383087907519\n",
      "validation loss: 791.6731049716473\n",
      "Epoch: 87\n",
      "training loss: 661.331332215241\n",
      "validation loss: 791.4191414356231\n",
      "Epoch: 88\n",
      "training loss: 661.664596942493\n",
      "validation loss: 799.6325348615646\n",
      "Epoch: 89\n",
      "training loss: 660.7413723179272\n",
      "validation loss: 791.0781320095062\n",
      "Epoch: 90\n",
      "training loss: 660.9088822501046\n",
      "validation loss: 791.1025917828083\n",
      "Epoch: 91\n",
      "training loss: 660.9355308549744\n",
      "validation loss: 790.8860832095146\n",
      "Epoch: 92\n",
      "training loss: 660.8224291886602\n",
      "validation loss: 790.7533230602742\n",
      "Epoch: 93\n",
      "training loss: 660.8701738664082\n",
      "validation loss: 791.0482379734516\n",
      "Epoch: 94\n",
      "training loss: 660.8505383133888\n",
      "validation loss: 791.0933016896248\n",
      "Epoch: 95\n",
      "training loss: 660.7815921664238\n",
      "validation loss: 791.0983625590801\n",
      "Epoch: 96\n",
      "training loss: 660.8992701768875\n",
      "validation loss: 791.0779254972934\n",
      "Epoch: 97\n",
      "training loss: 660.7832843712398\n",
      "validation loss: 791.0963592171669\n",
      "Epoch: 98\n",
      "training loss: 660.8934884727001\n",
      "validation loss: 791.0721007108689\n",
      "Epoch: 99\n",
      "training loss: 660.9539217250688\n",
      "validation loss: 791.5110313415528\n",
      "Epoch: 100\n",
      "training loss: 660.66690358775\n",
      "validation loss: 793.1621188521385\n",
      "Epoch: 101\n",
      "training loss: 660.9796112605503\n",
      "validation loss: 791.3556901752949\n",
      "Epoch: 102\n",
      "training loss: 660.7661315986088\n",
      "validation loss: 792.169894015789\n",
      "Epoch: 103\n",
      "training loss: 660.8736746140888\n",
      "validation loss: 790.9063129782677\n",
      "Epoch: 104\n",
      "training loss: 660.8224928745202\n",
      "validation loss: 793.013840675354\n",
      "Epoch: 105\n",
      "training loss: 660.6974079949515\n",
      "validation loss: 793.2091328561306\n",
      "Epoch: 106\n",
      "training loss: 661.0113341689109\n",
      "validation loss: 790.6520189762116\n",
      "Epoch: 107\n",
      "training loss: 660.783416638204\n",
      "validation loss: 791.0410020112992\n",
      "Epoch: 108\n",
      "training loss: 660.769010330098\n",
      "validation loss: 815.2321641921997\n",
      "Epoch: 109\n",
      "training loss: 660.6732888096677\n",
      "validation loss: 791.1256402492523\n",
      "Epoch: 110\n",
      "training loss: 665.2899114847183\n",
      "validation loss: 966.730614823103\n",
      "Epoch: 111\n",
      "training loss: 660.8915046044758\n",
      "validation loss: 799.3013478100299\n",
      "Epoch: 112\n",
      "training loss: 660.7156288972923\n",
      "validation loss: 791.110679101944\n",
      "Epoch: 113\n",
      "training loss: 660.7601933581489\n",
      "validation loss: 791.3015368908643\n",
      "Epoch: 114\n",
      "training loss: 660.8177723254477\n",
      "validation loss: 792.0153351724148\n",
      "Epoch: 115\n",
      "training loss: 660.842745579992\n",
      "validation loss: 795.3378217846155\n",
      "Epoch: 116\n",
      "training loss: 681.5746402297701\n",
      "validation loss: 791.2143854737282\n",
      "Epoch: 117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m train_model()\n",
      "Cell \u001b[0;32mIn[42], line 55\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch)\n\u001b[0;32m---> 55\u001b[0m     train()\n\u001b[1;32m     56\u001b[0m     curr_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m()\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_acc \u001b[38;5;241m>\u001b[39m best_acc:\n",
      "Cell \u001b[0;32mIn[42], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(f\"training loss: {total_loss / len(dataloaders['train'])}, training accuracy: {total_correct / len(dataloaders['eval'])}\")\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:74\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m prev_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Note on graph break below:\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# we need to graph break to ensure that aot respects the no_grad annotation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# graph break to allow the fully fused fwd-bwd-optimizer graph to be compiled.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# see https://github.com/pytorch/pytorch/issues/104053\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m     76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/grad_mode.py:186\u001b[0m, in \u001b[0;36mset_grad_enabled.__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 186\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
