{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "import time\n",
    "import scipy.io as sio\n",
    "import hdf5storage\n",
    "from multiprocessing import TimeoutError\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from aicspylibczi import CziFile\n",
    "from natsort import natsorted\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optical flow vectors, 10 frames for each cell\n",
    "from skimage.measure import centroid\n",
    "import skimage.measure as skm\n",
    "\n",
    "X = 10\n",
    "\n",
    "class CellBoxMaskPatch(torch.utils.data.Dataset):\n",
    "    #input will be a Directory name, function is TO DO\n",
    "    def __init__(\n",
    "        self,\n",
    "        files, \n",
    "        X=10):\n",
    "        \n",
    "        #take list of files and get data\n",
    "        \n",
    "        self.opticalflows = [] #list of dlows for the same cells\n",
    "        self.centroids = [] #list of centroids \n",
    "    \n",
    "        for (vid_type, num) in files:\n",
    "            of_address = os.path.join('opticalflow/', f'{vid_type}{num}')   \n",
    "            file_list = natsorted(os.listdir(of_address))    # sort the image files numerically by frame-index\n",
    "            n_frames = len(file_list)\n",
    "            ten_list = []\n",
    "            ten_list_mask = []\n",
    "            for k in range(n_frames):\n",
    "                of = np.load(of_address+'/{}.npz'.format(k)) #dictionary --> keys are vx, vy  [3, w, h]\n",
    "                vx = of['vx'][0]\n",
    "                vy = of['vy'][0]\n",
    "                #get cells --> these are 2 frames, we want boxes on all the cells in the frames in the future\n",
    "                #TO DO: Bounding boxes ???\n",
    "                ten_list.append([vx,vy])\n",
    "                \n",
    "\n",
    "                img = get_file(vid_type, num)\n",
    "                img_temp = img.read_image(C=0, Z=50)\n",
    "                img_temp = scale_img(img_temp[0].squeeze())\n",
    "                mask = binarize_video(img_temp)\n",
    "                ten_list_mask.append(mask[k])\n",
    "\n",
    "\n",
    "                if (k%X ==0):\n",
    "                    #here (or can change code, remove optical flow, use get cells to isolate cells and retun their optical flow)\n",
    "                    self.opticalflows.append(ten_list)\n",
    "                    ten_list = []\n",
    "                    self.frames.append(ten_list_mask)\n",
    "                    ten_list_mask = []\n",
    "                    #goal: 2 lists - one if a list of 10 centroids, and one is a list of 10 cells with opical flow\n",
    "        \n",
    "              \n",
    "    def __len__(self):\n",
    "        return len(self.opticalflows) #this should get all the lists of \n",
    "        \n",
    "\n",
    "\n",
    "    def get_cells(img, masked):\n",
    "        bboxes, num_cells, cell_areas = bounding_boxes(masked)\n",
    "        zoomed_cells = []\n",
    "        relative_centroids = []\n",
    "        for box in bboxes:\n",
    "            zoomed_cells.append([img[box[0]:box[2],box[1]:box[3]]])\n",
    "            relative_centroids.append(skimage.measure.centroid(masked[box[0]:box[2],box[1]:box[3]]))\n",
    "            \n",
    "        return zoomed_cells, bboxes, num_cells, cell_areas, relative_centroids, masked\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        flows = self.opticalflows[idx]\n",
    "        centroids = self.centroids[idx]\n",
    "    \n",
    "\n",
    "        return flows, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "mip_video_files = [\n",
    "    ('processed', 3),\n",
    "    ('processed', 6),\n",
    "    ('processed', 9)\n",
    "]\n",
    "\n",
    "dataset = CellBoxMaskPatch(mip_video_files, X) # file, S, T\n",
    "\n",
    "train, eval, test = random_split(dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "input_datasets = {}\n",
    "input_datasets[\"train\"] = train\n",
    "input_datasets[\"eval\"] = eval\n",
    "input_datasets[\"test\"] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, mode_box, mode_mask, mode_patch):\n",
    "    current_centroids = [b[1] for b in batch]\n",
    "    current_flows = [b[0] for b in batch]\n",
    "\n",
    "\n",
    "    return current_flows, current_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(\n",
    "    input_datasets['train'],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn(batch)\n",
    ")\n",
    "\n",
    "dataloaders['test'] = torch.utils.data.DataLoader(\n",
    "    input_datasets['test'],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn(batch)\n",
    ")\n",
    "\n",
    "dataloaders['eval'] = torch.utils.data.DataLoader(\n",
    "    input_datasets['eval'],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn(batch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloaders['eval']:\n",
    "    print(\"Input:\", batch[0].shape, \"Centroids\", batch[1].shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
