{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ca9078-71cf-41d4-aec7-2b775ab3188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f2c8fb31410>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aicspylibczi import CziFile\n",
    "import czifile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import ffmpeg\n",
    "import time\n",
    "import pandas as pd\n",
    "# from cellpose import io, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import glob\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "cudnn.benchmark = True\n",
    "from VideoLoaders import *\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d880c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import mahotas #: Module(\"mahotas\")\n",
    "\n",
    "\n",
    "def extract_traces_sparse(frames, masks, hist=2):\n",
    "    bboxes, num_cells, areas = bounding_boxes(masks[0])\n",
    "    vid_data = []\n",
    "    for i in range(num_cells):\n",
    "        #print(\"Extracting cell \", i)\n",
    "        data = track_cells(i, frames, masks, padding=0, history_length=hist, verbose=False)\n",
    "        vid_data.append(data)\n",
    "    return(vid_data)\n",
    "\n",
    "def shape_features(binary, feature_length=20, num_samples=180):\n",
    "    def radial_distance(binary, theta):\n",
    "        height, width = binary.shape\n",
    "        center = [width // 2, height // 2]\n",
    "        def test_r(r):\n",
    "            x_test, y_test = center[0] + r*np.cos(theta), center[1] + r*np.sin(theta)\n",
    "            if(x_test >= width or y_test > height or x_test < 0 or y_test < 0):\n",
    "                return(False)\n",
    "            return(binary[int(y_test), int(x_test)])\n",
    "        # calculate distance to the nearest pixel\n",
    "        r = max(height, width)\n",
    "        while(not test_r(r)): # start from edge come inside until hit cell\n",
    "            r -= 1\n",
    "        return(r)\n",
    "\n",
    "    test_angles = np.linspace(0, 2*np.pi, num_samples)\n",
    "    distances = np.array([radial_distance(binary, angle) for angle in test_angles])\n",
    "    fft_coefficients = np.fft.rfft(distances)\n",
    "\n",
    "    features = np.abs(fft_coefficients[:feature_length])\n",
    "    features = features / np.sum(features)\n",
    "    return(features, (distances, fft_coefficients))\n",
    "\n",
    "def featurize(cell_data, index):\n",
    "    image, binary = cell_data['patches'][index], cell_data['masks'][index].astype(np.uint8)\n",
    "    zernike = mahotas.features.zernike_moments(binary, max(binary.shape)/2, degree=8)\n",
    "    #zernike = zernike / zernike.sum()\n",
    "    haralick = mahotas.features.haralick(image.astype(np.uint16)).mean(axis=0)\n",
    "    #haralick = haralick / haralick.sum()\n",
    "    shape, info = shape_features(binary, 20)\n",
    "    #print(f\"Zernike: {zernike.shape}, Haralick: {haralick.shape}, Radial Shape: {shape.shape}\")\n",
    "    return(np.concatenate([zernike, haralick, shape]))\n",
    "\n",
    "class VideoDataProcessed:\n",
    "    def __init__(self, files, sequence_length=5, channel=0):\n",
    "        self.data = {}\n",
    "        self.all_traces = []\n",
    "        self.seq_length = sequence_length\n",
    "        self.channel = channel\n",
    "        self.videos = {}\n",
    "        for category, num in files:\n",
    "            print(f\"Loading in processed {num}\")\n",
    "            assert category == 'processed', \"Can't load non processed file\"\n",
    "            video = get_file(category, num)\n",
    "            self.videos[num] = video\n",
    "        self.num_vids = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_vids\n",
    "\n",
    "    def extract_planes(self, num, zplanes, hist_length):\n",
    "        for z in zplanes:\n",
    "            self.extract_slice_traces(num, z, hist_length)\n",
    "    \n",
    "    def extract_slice_traces(self, num, zPlane, hist_length=2):\n",
    "        assert num in self.videos.keys(), f\"Video {num} not found\"\n",
    "        \n",
    "        video = self.videos[num]\n",
    "        frames, shp = video.read_image(C=self.channel, S=0, Z=zPlane)\n",
    "        frames = scale_img(frames.squeeze())\n",
    "        print(f\"vid {num} zplane {zPlane} with frames: {frames.shape}\")\n",
    "        masks = binarize_video(frames)\n",
    "        N = len(frames)\n",
    "        s = 0\n",
    "        for i in range(N // self.seq_length):\n",
    "            print(f\"Extracting traces from {s}:{s+self.seq_length}\")\n",
    "            data = extract_traces_sparse(frames[s:s+self.seq_length], masks[s:s+self.seq_length], hist=hist_length)\n",
    "            s += self.seq_length\n",
    "            self.all_traces = self.all_traces + data\n",
    "        \n",
    "        if(N % self.seq_length > 0):\n",
    "            data = extract_traces_sparse(frames[-1*self.seq_length:], masks[-1*self.seq_length:], hist=hist_length)\n",
    "            self.all_traces = self.all_traces + data\n",
    "\n",
    "\n",
    "class SparseMIPVideo:\n",
    "    def __init__(self, files, sequence_length, hist_length=2):\n",
    "        self.data = {}\n",
    "        self.all_traces = []\n",
    "        self.N = sequence_length\n",
    "        for category, num in files:\n",
    "            print(f\"Loading in MIP {num}\")\n",
    "            assert category == 'mip', \"Can't load non Mip file\"\n",
    "            video = get_file(category, num)\n",
    "            frames, shp = video.read_image(C=0)\n",
    "            frames = scale_img(frames.squeeze())\n",
    "            print(f\"frames {num}: {frames.shape}\")\n",
    "            masks = binarize_video(frames)\n",
    "\n",
    "            print(f\"Finished loading frames and masks for MIP {num}\")\n",
    "\n",
    "            N = len(frames)\n",
    "            s = 0\n",
    "        \n",
    "            for i in range(N // sequence_length):\n",
    "                print(f\"Extracting traces from {s}:{s+sequence_length}\")\n",
    "                data = extract_traces_sparse(frames[s:s+sequence_length], masks[s:s+sequence_length], hist=hist_length)\n",
    "                s += sequence_length\n",
    "                self.all_traces = self.all_traces + data\n",
    "            \n",
    "            if(N % sequence_length > 0):\n",
    "                data = extract_traces_sparse(frames[-1*sequence_length:], masks[-1*sequence_length:], hist=hist_length)\n",
    "                self.all_traces = self.all_traces + data\n",
    "\n",
    "    def featurize_traces(self):\n",
    "        self.featurized_frames = []\n",
    "        for i, trace in enumerate(self.all_traces):\n",
    "            if(i % 100 == 0):\n",
    "                print(i)\n",
    "            trajectory_features = np.array([featurize(trace, index) for index in range(5)])\n",
    "            self.featurized_frames.append(trajectory_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed79b05-c94d-476e-b64d-a577539b67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import centroid\n",
    "import skimage.measure as skm\n",
    "\n",
    "max_padding =  250\n",
    "\n",
    "box_shape = (180, 180) #TO DO: find the biggest box and set it to this\n",
    "X = 10\n",
    "\n",
    "class CellBoxMaskPatch(torch.utils.data.Dataset):\n",
    "    #input will be a Directory name, function is TO DO\n",
    "    def __init__(\n",
    "        self,\n",
    "        files, \n",
    "        X=X):\n",
    "        \n",
    "        self.mips_extractor = SparseMIPVideo(files)\n",
    "\n",
    "        for i in files:\n",
    "            self.video_extractor.extract_all_traces(i[1], X)\n",
    "        \n",
    "        \n",
    "        self.cell_dict = []\n",
    "\n",
    "        for key in self.video_extractor.data:\n",
    "            entry = self.video_extractor.data[key][\"traces\"]\n",
    "            for cell in entry:\n",
    "                patches = [np.array(p) for p in cell[\"patches\"]]\n",
    "                boxes = [np.array(b) for b in cell['boxes']]\n",
    "                masks = [np.array(m) for m in cell['masks']]\n",
    "                \n",
    "                self.cell_dict.append((boxes, masks, patches)) #cell dict is a list of 3 types by sequence\n",
    "\n",
    "        self.num_cells = len(self.cell_dict) #this is a list of how many sequences we have\n",
    "              \n",
    "    def __len__(self):\n",
    "        return self.num_cells\n",
    "        \n",
    "\n",
    "    def get_centroids(self, boxes, masks):\n",
    "        N = len(masks)\n",
    "        res = []\n",
    "        centroids = [skm.centroid(binary.astype(np.uint8)) for binary in masks]\n",
    "        for i in range(N):\n",
    "            c = centroids[i]\n",
    "            ymin, xmin = boxes[i][:2]\n",
    "            res.append([xmin+c[0], ymin+c[1]])\n",
    "        return(np.array(res) - res[0]) \n",
    "   \n",
    "    def pad_arrays(self, array, pad_amt=max_padding):\n",
    "    \n",
    "        pad_width = ((0, pad_amt - array.shape[0]), (0, pad_amt - array.shape[1]))\n",
    "\n",
    "        padded_array = np.pad(array, pad_width, mode='constant')\n",
    "        return padded_array\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cell_sequences = self.cell_dict[idx]  #this is the first sequence of 10 cells\n",
    "        boxes = cell_sequences[0]\n",
    "        masks = cell_sequences[1]\n",
    "        patches = cell_sequences[2]\n",
    "\n",
    "\n",
    "        for cell_mask_num in np.arange(len(masks)): #should be sequence length (10) masks\n",
    "                \n",
    "                cell_time = np.array(masks[cell_mask_num], dtype=np.int32)\n",
    "                cell_time = np.where(cell_time >= 0, cell_time, 1)\n",
    "                cell_time = self.pad_arrays(cell_time)\n",
    "                masks[cell_mask_num] = cell_time\n",
    "                cell_time_patch = np.array(patches[cell_mask_num], dtype=np.int32)\n",
    "\n",
    "                cell_time_patch = self.pad_arrays(cell_time_patch)\n",
    "\n",
    "                patches[cell_mask_num] = cell_time_patch\n",
    "\n",
    "\n",
    "        centroids = self.get_centroids(boxes, masks)\n",
    "    \n",
    "\n",
    "        return centroids, masks, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f44453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "import VideoLoaders\n",
    "\n",
    "X = 10\n",
    "processed_video_files = [\n",
    "    ('processed', 3),\n",
    "]\n",
    "processed_dataset = VideoLoaders.VideoDataProcessed(processed_video_files)\n",
    "processed_dataset.extract_slice_traces(3, 50)\n",
    "\n",
    "# train, val, test = random_split(processed_dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "# input_datasets = {}\n",
    "# input_datasets[\"train\"] = train\n",
    "# input_datasets[\"val\"] = val\n",
    "# input_datasets[\"test\"] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bfa093",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ab035",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e146ac4d-71f3-4f35-8000-175fa16b7fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in processed 3\n",
      "Loading dicty_factin_pip3-03_processed.czi with dims [{'X': (0, 475), 'Y': (0, 2048), 'Z': (0, 114), 'C': (0, 2), 'T': (0, 90), 'S': (0, 1)}]\n",
      "vid 3 zplane 50 with frames: (90, 2048, 475)\n",
      "Extracting traces from 0:5\n",
      "Extracting traces from 5:10\n",
      "Extracting traces from 10:15\n",
      "Extracting traces from 15:20\n",
      "Extracting traces from 20:25\n",
      "Extracting traces from 25:30\n",
      "Extracting traces from 30:35\n",
      "Extracting traces from 35:40\n",
      "Extracting traces from 40:45\n",
      "Extracting traces from 45:50\n",
      "Extracting traces from 50:55\n",
      "Extracting traces from 55:60\n",
      "Extracting traces from 60:65\n",
      "Extracting traces from 65:70\n",
      "Extracting traces from 70:75\n",
      "Extracting traces from 75:80\n",
      "Extracting traces from 80:85\n",
      "Extracting traces from 85:90\n"
     ]
    }
   ],
   "source": [
    "import VideoLoaders\n",
    "\n",
    "X = 10\n",
    "processed_video_files = [\n",
    "    ('processed', 3),\n",
    "]\n",
    "processed_dataset = VideoLoaders.VideoDataProcessed(processed_video_files)\n",
    "processed_dataset.extract_slice_traces(3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752460f6-f7a6-4b21-978d-d494889ad2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VideoLoaders.VideoDataProcessed at 0x7f2c8fbbcd90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b623d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
