{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicspylibczi import CziFile\n",
    "import czifile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import ffmpeg\n",
    "import time\n",
    "import pandas as pd\n",
    "from cellpose import io, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': (0, 475),\n",
       " 'Y': (0, 2048),\n",
       " 'Z': (0, 114),\n",
       " 'C': (0, 2),\n",
       " 'T': (0, 241),\n",
       " 'S': (0, 1)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = \"/home/ssa2206/dicty_factin_pip3-06_processed.czi\"\n",
    "video = CziFile(fname)\n",
    "video.get_dims_shape()[0]\n",
    "#X and Y are coords\n",
    "#Z is the Z Slice\n",
    "#C is channels\n",
    "#T is time\n",
    "#S is the \"scenes\"/angles but there's only one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 1), ('T', 1), ('C', 1), ('Z', 1), ('Y', 2048), ('X', 475)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z50, shp = video.read_image(S=0, Z=50, C=0, T=50) \n",
    "shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(timestep=-1, z_plane=50, czi=video, channel=0):\n",
    "    dims = video.get_dims_shape()[0]\n",
    "    \n",
    "    timestep = timestep % dims['T'][-1]\n",
    "    z_plane = z_plane % dims['Z'][-1]\n",
    "    img, shp = video.read_image(S=0, Z=z_plane, T=timestep, C=channel)\n",
    "    #print(shp)\n",
    "    return(img.squeeze()) # returns (channels, Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = get_image(50, 100, video, channel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m masks, flows, styles \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mCellposeModel(model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcyto3\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39meval(\u001b[43mtest_img\u001b[49m,\n\u001b[1;32m      2\u001b[0m                             diameter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_img' is not defined"
     ]
    }
   ],
   "source": [
    "masks, flows, styles = models.CellposeModel(model_type='cyto3').eval(test_img,\n",
    "                            diameter=None, channels=[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape\n",
    "np.max(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Displaying the image with the custom colormap\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mmasks\u001b[49m, cmap\u001b[38;5;241m=\u001b[39mcmap)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()  \u001b[38;5;66;03m# Add a colorbar to show the mapping of values to colors\u001b[39;00m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZSlice 50 with each label labeled as color\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masks' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "#8 colors for this piece\n",
    "colors = ['black', 'red', 'blue', 'green', 'yellow', 'purple', 'orange', 'brown', 'cyan']\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Displaying the image with the custom colormap\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(masks, cmap=cmap)\n",
    "plt.colorbar()  # Add a colorbar to show the mapping of values to colors\n",
    "plt.title('ZSlice 50 with each label labeled as color')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.load(\"/home/ssa2206/pip3-06_processed_frame_masks_z50.npy\")\n",
    "#this is all the timesteps of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/contours.cpp:192: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Skip background\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m x, y, w, h \u001b[38;5;241m=\u001b[39m \u001b[43mget_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# valid_rectangles[count] = (x1, y1, w1, h1)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# count +=1\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mget_bounding_box\u001b[0;34m(mask, cellID, padding)\u001b[0m\n\u001b[1;32m      8\u001b[0m binary_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(binary_array \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Find contours\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindContours\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRETR_EXTERNAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHAIN_APPROX_SIMPLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(contours) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContour not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/contours.cpp:192: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_bounding_box(mask, cellID, padding=3):\n",
    "    binary_array = (mask == cellID)\n",
    "    # Convert binary array to binary image\n",
    "    binary_image = np.uint8(binary_array * 255)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if(len(contours) == 0):\n",
    "        print(\"Contour not found\")\n",
    "        return(-1)\n",
    "    # Get the bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    \n",
    "    # Apply padding\n",
    "    x -= padding\n",
    "    y -= padding\n",
    "    w += 2 * padding\n",
    "    h += 2 * padding    \n",
    "    return(x, y, w, h)\n",
    "\n",
    "#masks = np.uint8(masks)\n",
    "\n",
    "# Get unique colors in the image\n",
    "unique_colors = np.unique(masks)\n",
    "\n",
    "# Create a copy of the image for visualization\n",
    "image_with_boxes = np.copy(masks)\n",
    "\n",
    "# Draw bounding boxes for each unique color\n",
    "already_pos = []\n",
    "valid_rectangles = {}\n",
    "count = 1\n",
    "for color in unique_colors:\n",
    "    if color == 0:  # Skip background\n",
    "        continue\n",
    "    x, y, w, h = get_bounding_box(masks, color)\n",
    "    # valid_rectangles[count] = (x1, y1, w1, h1)\n",
    "    # count +=1\n",
    "    if x != -1:\n",
    "        for n in already_pos:\n",
    "            count+=1\n",
    "            x1, y1, w1, h1, = n\n",
    "            x2 = x1+w1\n",
    "            y2= y2+h1\n",
    "            if (x1 < x < x2 and y1 < y < y2 ):\n",
    "                #new box should be the biggest box posible\n",
    "                small_x = x1 if x1 < x else x\n",
    "                small_y = y1 if y1 < y else y\n",
    "                big_x = x2 if x2 > (x+w) else (x+w)\n",
    "                big_y = y2 if y2 > (y+h) else (y+h)\n",
    "\n",
    "                print(small_x, small_y, big_x, big_y)\n",
    "\n",
    "                # valid_rectangles[count] = (small_x, small_y, big_x-small_x, big_y-small_y)\n",
    "                cv2.rectangle(image_with_boxes, (small_x, small_y), (big_x, big_y), (255, 0, 0), 10)\n",
    "\n",
    "                print(\"breaking for\", color)\n",
    "                break\n",
    "        valid_rectangles[count] = (x, y, x+w, y+h)\n",
    "    already_pos.append((x, y, w, h))\n",
    "    # for rectangle in valid_rectangles.values():\n",
    "    #     cv2.rectangle(image_with_boxes, (rectangle[0], rectangle[1]), (rectangle[2]+rectangle[0], rectangle[1]+rectangle[3]), (255, 0, 0), 10)\n",
    "\n",
    "    \n",
    "# Display the image with bounding boxes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image_with_boxes, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Image with Bounding Boxes')\n",
    "\n",
    "#display the color maps\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(masks, cmap=cmap)\n",
    "plt.colorbar()  # Add a colorbar to show the mapping of values to colors\n",
    "plt.title('ZSlice 50 with each label labeled as color')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CziVideo:\n",
    "    def __init__(self, fpath):\n",
    "        self.file = fpath\n",
    "        self.video = CziFile(fpath)\n",
    "        self.dims = self.video.get_dims_shape()[0]\n",
    "\n",
    "        self.num_frames = self.dims['T'][-1]\n",
    "        self.num_zslices = self.dims['Z'][-1]\n",
    "        print(f\"Video with {self.num_frames} frames, {self.num_zslices} z slices\")\n",
    "\n",
    "        self.num_cells_per_frame = {}\n",
    "        self.cell_masks = {}\n",
    "\n",
    "    def get_plane(self, z_plane, scale=True):\n",
    "        plane, shp = self.video.read_image(S=0, Z=z_plane, C=self.channel)\n",
    "        if(scale):\n",
    "            plane = self.scale_img(plane)\n",
    "\n",
    "        return(plane.squeeze())\n",
    "    \n",
    "    def get_image(self, z_plane, timestep, channel=0, scale=True):\n",
    "        timestep = timestep % self.num_frames\n",
    "        z_plane = z_plane % self.num_zslices\n",
    "        img, shp = self.video.read_image(S=0, Z=z_plane, T=timestep, C=channel)\n",
    "        img = img.squeeze()\n",
    "        if(scale):\n",
    "            img = self.scale_img(img)\n",
    "        return(img) # returns (channels, Y, X)\n",
    "\n",
    "    def scale_img(self, img):\n",
    "        lower_bound = np.percentile(img, 1)\n",
    "        upper_bound = np.percentile(img, 99.9)\n",
    "        I = (img - lower_bound) / (upper_bound - lower_bound)\n",
    "        I = np.clip(I, 0, 1)\n",
    "        return(I)\n",
    "\n",
    "    def load_segmentation_masks(self, zplane=50, verbose=False):\n",
    "        print(f\"Loading segmentation masks for zplane {zplane}\")\n",
    "        num_cells = []\n",
    "        cell_masks = []\n",
    "        flows = []\n",
    "        styles = []\n",
    "        for frame in range(self.dims['T'][-1]):\n",
    "            if(verbose):\n",
    "                print(f\"Computing for timestep {frame}\")\n",
    "            img = self.get_image(zplane, frame)\n",
    "            mask, flow, style = models.CellposeModel(model_type='cyto3').eval(img,\n",
    "                                    diameter=None, channels=[0,0])\n",
    "            cell_masks.append(mask)\n",
    "            flows.append(flow)\n",
    "            styles.append(style)\n",
    "            N = len(np.unique(masks))\n",
    "            num_cells.append(N)\n",
    "\n",
    "        self.num_cells_per_frame[zplane] = num_cells\n",
    "        self.cell_masks[zplane] = {\n",
    "            \"masks\" : np.array(cell_masks),\n",
    "            \"flows\" : flows,\n",
    "            \"styles\" : styles,\n",
    "        }\n",
    "\n",
    "    def calculate_bounding_boxes(self, zplane=50, verbose=False, padding=10):\n",
    "        print(self.cell_masks.keys(), zplane in self.cell_masks.keys())\n",
    "        masks = self.cell_masks[zplane]['masks']\n",
    "        bounding_boxes = {}\n",
    "        for frame, num_cells_in_frame in enumerate(self.num_cells_per_frame[50]):\n",
    "            mask = masks[frame]\n",
    "            bounding_boxes[frame] = []\n",
    "            for cell_id in range(num_cells_in_frame):\n",
    "                if verbose:\n",
    "                    print(f'Fetching cell {cell_id} from frame {frame}')\n",
    "                binary = np.uint8((mask==cell_id) * 255)\n",
    "                contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if(len(contours) == 0):\n",
    "                    if(verbose):\n",
    "                        print(\"contour not found\")\n",
    "                    \n",
    "                else:\n",
    "                    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "                    x -= padding\n",
    "                    y -= padding\n",
    "                    w += 2 * padding\n",
    "                    h += 2 * padding\n",
    "                    bounding_boxes[frame].append((x, y, w, h))\n",
    "        self.cell_masks[zplane]['boxes'] = bounding_boxes\n",
    "        return(bounding_boxes)\n",
    "            \n",
    "\n",
    "\n",
    "    def find_bounding_box(self, mask, cellID, padding=3):\n",
    "        binary_array = (mask == cellID)\n",
    "        # Convert binary array to binary image\n",
    "        binary_image = np.uint8(binary_array * 255)\n",
    "        \n",
    "        # Find contours\n",
    "        \n",
    "        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        print(f\"Contours size {len(contours)}\")\n",
    "        # Get the bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        \n",
    "        # Apply padding\n",
    "        x -= padding\n",
    "        y -= padding\n",
    "        w += 2 * padding\n",
    "        h += 2 * padding\n",
    "        return(x, y, w, h)\n",
    "\n",
    "    def draw_bounding_box(self, image, rec, value, thickness=3):\n",
    "        # value is what pixel val want to put there\n",
    "        x, y, w, h = rec\n",
    "        # Draw bounding box over image\n",
    "        bounding_box_image = cv2.rectangle(image, (x, y), (x + w, y + h), value, thickness)\n",
    "        \n",
    "        return bounding_box_image, (x, y, w, h)\n",
    "\n",
    "\n",
    "    def get_cell_mask(self, zplane, frame, cell_num):\n",
    "        if(len(self.cell_masks) > 0 and zplane in self.cell_masks.keys()):\n",
    "            masks = self.cell_masks[zplane][\"masks\"]\n",
    "            if(cell_num < self.num_cells_per_frame[zplane][frame]):\n",
    "                print(f\"Fetching mask for cell {cell_num} out of {self.num_cells_per_frame[zplane][frame]} cells in frame\")\n",
    "                return(masks[frame] == cell_num)\n",
    "            else:\n",
    "                print(f\"Requested cell id {cell_num} out of range. This frame has only {self.num_cells_per_frame[zplane][frame]} cells\")\n",
    "                return(-1)\n",
    "        else:\n",
    "            print(\"This zplane has not loaded masks yet. Try running load_segmentation_masks(zplane) first!\")\n",
    "            return(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 1), ('T', 241), ('C', 1), ('Z', 1), ('Y', 2048), ('X', 475)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
